# LangChain Learning Journey

A structured collection of LangChain implementations and learnings, organized by topic.

## ğŸ“ Project Structure

```
langchain-course/
â”œâ”€â”€ 01-rag-basics/              # RAG implementation
â”‚   â”œâ”€â”€ main.py                 # Query system
â”‚   â”œâ”€â”€ ingestion.py            # Document processing
â”‚   â”œâ”€â”€ mediumblog1.txt         # Sample document
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ 02-agents-and-tools/        # AI agents with ReAct
â”‚   â”œâ”€â”€ callbacks.py            # Debug handlers
â”‚   â”œâ”€â”€ main_with_agent_executor.py
â”‚   â”œâ”€â”€ demo_tool_description.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ docs/                       # Comprehensive documentation
â”‚   â”œâ”€â”€ RAG_IMPLEMENTATION_EXPLAINED.md
â”‚   â”œâ”€â”€ FUNCTION_CALLING_EXPLAINED.md
â”‚   â”œâ”€â”€ FUNCTION_CALLING_VS_REACT.md
â”‚   â”œâ”€â”€ CREATE_TOOL_CALLING_AGENT_EXPLAINED.md
â”‚   â”œâ”€â”€ AGENT_EXECUTOR_EXPLAINED.md
â”‚   â”œâ”€â”€ COMPARISON.md
â”‚   â”œâ”€â”€ COHERE_SETUP.md
â”‚   â””â”€â”€ GITHUB_UPLOAD_GUIDE.md
â”‚
â”œâ”€â”€ .env                        # API keys (not committed)
â”œâ”€â”€ .gitignore                  # Git ignore rules
â”œâ”€â”€ pyproject.toml              # Dependencies (uv)
â”œâ”€â”€ uv.lock                     # Lock file
â””â”€â”€ README.md                   # This file
```

## ğŸ¯ Learning Modules

### [01 - RAG Basics](./01-rag-basics/)
Learn Retrieval-Augmented Generation from scratch:
- âœ… Document loading and chunking
- âœ… Vector embeddings with Cohere
- âœ… Pinecone vector database
- âœ… Semantic search
- âœ… Answer generation with Gemini

**Time**: ~1-2 hours  
**Difficulty**: Beginner

### [02 - Agents and Tools](./02-agents-and-tools/)
Build AI agents using the ReAct pattern:
- âœ… Manual agent loops
- âœ… Function calling
- âœ… Tool descriptions
- âœ… AgentExecutor
- âœ… Debugging with callbacks

**Time**: ~1-2 hours  
**Difficulty**: Intermediate

### Coming Soon...
- 03 - Conversation Memory
- 04 - Advanced RAG (Re-ranking, Hybrid Search)
- 05 - LangGraph Workflows
- 06 - Production Deployment

## ï¿½ Quick Start

### 1. Install Dependencies
```bash
# Using uv (recommended)
uv sync

# Or using pip
pip install -r requirements.txt
```

### 2. Set Up API Keys
Create a `.env` file:
```bash
GOOGLE_API_KEY=your_gemini_key
COHERE_API_KEY=your_cohere_key
PINECONE_API_KEY=your_pinecone_key
INDEX_NAME=your_index_name
```

### 3. Get Free API Keys
- **Gemini**: https://makersuite.google.com/app/apikey
- **Cohere**: https://dashboard.cohere.com/
- **Pinecone**: https://www.pinecone.io/

### 4. Start Learning!
```bash
# Module 1: RAG
cd 01-rag-basics
python ingestion.py  # One-time setup
python main.py       # Query the system

# Module 2: Agents
cd ../02-agents-and-tools
python demo_tool_description.py
```

## ğŸ—ï¸ Tech Stack

| Component | Technology | Why? |
|-----------|-----------|------|
| **Framework** | LangChain | Industry standard for LLM apps |
| **LLM** | Gemini 2.5 Flash Lite | Free tier, fast, capable |
| **Embeddings** | Cohere v3.0 | Free tier, 1024-d vectors |
| **Vector DB** | Pinecone | Managed, scalable, easy |
| **Package Manager** | uv | 10-100x faster than pip |

## ğŸ“š Documentation

All detailed explanations are in the `/docs` folder:

### RAG Deep Dives
- **RAG_IMPLEMENTATION_EXPLAINED.md**: Complete RAG walkthrough
- **COHERE_SETUP.md**: Getting Cohere API key

### Agent Deep Dives
- **FUNCTION_CALLING_EXPLAINED.md**: What is function calling?
- **FUNCTION_CALLING_VS_REACT.md**: Function calling vs ReAct
- **CREATE_TOOL_CALLING_AGENT_EXPLAINED.md**: Agent creation
- **AGENT_EXECUTOR_EXPLAINED.md**: AgentExecutor features
- **COMPARISON.md**: Manual vs automated agents

### Guides
- **GITHUB_UPLOAD_GUIDE.md**: How to push to GitHub

## ğŸ“ Learning Path

**Recommended order**:

1. **Start with RAG** (`01-rag-basics/`)
   - Understand embeddings and vector search
   - See how retrieval works
   - Build your first RAG system

2. **Then Agents** (`02-agents-and-tools/`)
   - Learn the ReAct pattern
   - Understand function calling
   - Compare manual vs automated approaches

3. **Read Documentation** (`docs/`)
   - Deep dive into concepts
   - Understand trade-offs
   - Learn best practices

4. **Experiment**
   - Modify chunk sizes
   - Add new tools
   - Try different models
   - Build your own projects

## ğŸ”§ Customization

### Use Different Models

**LLM**:
```python
# Gemini Pro (more capable)
llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro")

# Claude
llm = ChatAnthropic(model="claude-3-sonnet")
```

**Embeddings**:
```python
# OpenAI
embeddings = OpenAIEmbeddings()

# Multilingual Cohere
embeddings = CohereEmbeddings(model="embed-multilingual-v3.0")
```

### Add Your Own Documents

Replace `mediumblog1.txt` with your own:
```python
loader = TextLoader("your_document.txt")
# Or use other loaders:
# PDFLoader, CSVLoader, WebBaseLoader, etc.
```

## ğŸ“Š What You'll Build

By completing all modules, you'll have:
- âœ… Working RAG system
- âœ… Custom AI agents
- âœ… Understanding of LangChain patterns
- âœ… Production-ready code examples
- âœ… Comprehensive documentation

## ğŸ› Troubleshooting

### API Quota Issues
- Gemini: Free tier resets daily
- Cohere: 100 calls/min free
- Pinecone: 1 index free

### Dimension Mismatch
Ensure embeddings match Pinecone index:
- Cohere `embed-english-v3.0`: 1024 dimensions
- Set Pinecone index to 1024 dimensions

### Import Errors
```bash
# Reinstall dependencies
uv sync

# Or
pip install -r requirements.txt
```

## ğŸ¤ Contributing

Feel free to:
- Add new modules
- Improve documentation
- Fix bugs
- Share your learnings

## ğŸ“„ License

MIT

## ğŸ™ Acknowledgments

- LangChain team for the amazing framework
- Google for Gemini
- Cohere for embeddings
- Pinecone for vector database

---

**Happy Learning! ğŸš€**

*This is a living repository - new modules and improvements added regularly*
